{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "from time import strftime\n",
    "import os\n",
    "from urllib.request import urlopen as uReq\n",
    "from urllib.request import Request\n",
    "import itertools\n",
    "import json\n",
    "import re\n",
    "\n",
    "\n",
    "import requests_html\n",
    "from requests_html import HTMLSession\n",
    "\n",
    "import selenium\n",
    "#driver = webdriver.Firefox(executable_path=r'C:\\Users\\mstre\\Dropbox\\0Big_data\\Xpdia\\Mathieu\\01_webscrap\\geckodriver.exe')\n",
    "#driver.get('http://inventwithpython.com')\n",
    "\n",
    "from selenium import webdriver\n",
    "import selenium.webdriver.support.ui as ui\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "\n",
    "from flask import jsonify\n",
    "\n",
    "import contextlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Print current working directory C:\\Users\\mstre\\Dropbox\\0Big_data\\Xpdia\\Mathieu\n"
     ]
    }
   ],
   "source": [
    "print(\"Print current working directory\", os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape(linki):  # scrape function \n",
    "\n",
    "    # start firefox and scrape content\n",
    "    \n",
    "    driver = webdriver.Firefox()\n",
    "\n",
    "    driver.get(linki)\n",
    "    print('B',linki)\n",
    "\n",
    "    element = WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.CLASS_NAME, \"norm\")))\n",
    "    \n",
    "    html = driver.page_source    \n",
    "    \n",
    "    soup = BeautifulSoup(html, \"lxml\")\n",
    "      \n",
    "    table = soup.find(\"table\", attrs={\"id\": \"sr\"})\n",
    "\n",
    "    tr_ = soup.find_all(\"tr\", class_='norm')\n",
    "    tr_2=soup.find_all(\"tr\", class_='norm2')\n",
    "    \n",
    "    tdf1=pd.DataFrame(tr_,columns=['A,','B,','C,'])\n",
    "    tdf2=pd.DataFrame(tr_2,columns=['A,','B,','C,'])\n",
    "    tdf=pd.concat([tdf1,tdf2]) \n",
    "    driver.close()\n",
    "    \n",
    "    return tdf;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A http://www.city-data.com//advanced/search.php#body?fips=0&csize=l&sc=2&sd=0&states=ALL&near=&nam_crit1=1033&b1033=11500&e1033=MAX&i1033=0&nam_crit2=1027&b1027=MIN&e1027=MAX&i1027=0&ps=20&p=340\n",
      "B http://www.city-data.com//advanced/search.php#body?fips=0&csize=l&sc=2&sd=0&states=ALL&near=&nam_crit1=1033&b1033=11500&e1033=MAX&i1033=0&nam_crit2=1027&b1027=MIN&e1027=MAX&i1027=0&ps=20&p=340\n"
     ]
    },
    {
     "ename": "TimeoutException",
     "evalue": "Message: \n",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTimeoutException\u001b[0m                          Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-47-68478db645a4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'A'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlinki\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m     \u001b[0mtdf_city_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtdf_city_data\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mscrape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlinki\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Scraped'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-46-ea99e2c7b3c7>\u001b[0m in \u001b[0;36mscrape\u001b[1;34m(linki)\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'B'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlinki\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m     \u001b[0melement\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mWebDriverWait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdriver\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0muntil\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mEC\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpresence_of_element_located\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mBy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCLASS_NAME\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"norm\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[0mhtml\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdriver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpage_source\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\selenium\\webdriver\\support\\wait.py\u001b[0m in \u001b[0;36muntil\u001b[1;34m(self, method, message)\u001b[0m\n\u001b[0;32m     78\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[0mend_time\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     79\u001b[0m                 \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 80\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mTimeoutException\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscreen\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstacktrace\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     81\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     82\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0muntil_not\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m''\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTimeoutException\u001b[0m: Message: \n"
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "# initiatilize\n",
    "tdf_city_data = pd.DataFrame(columns=['A,','B,','C,'])\n",
    "\n",
    "# scrape\n",
    "for i in range(340,341):    \n",
    "    \n",
    "    start_link = 'http://www.city-data.com//advanced/search.php#body?fips=0&csize=l&sc=2&sd=0&states=ALL&near=&nam_crit1=1033&b1033=11500&e1033=MAX&i1033=0&nam_crit2=1027&b1027=MIN&e1027=MAX&i1027=0&ps=20&p='\n",
    "    \n",
    "    linki=start_link+str(i)\n",
    "    \n",
    "    print('A',linki)\n",
    "    \n",
    "    tdf_city_data=pd.concat([tdf_city_data,scrape(linki)]) \n",
    "    \n",
    "    print('Scraped',i)\n",
    "    \n",
    "    i=i+1\n",
    "    \n",
    "     # save content to csv file\n",
    "\n",
    "    file_to_save = 'tdf_city_data.csv'\n",
    "    \n",
    "    if not os.path.exists(file_to_save): \n",
    "        tdf_city_data.to_csv(file_to_save,sep = \"|\",index=False)\n",
    "        \n",
    "    else:\n",
    "        tdf_city_data.to_csv(file_to_save,sep = \"|\",mode = 'a',index=False, header=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Show that the code works at least \"once\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Firefox()\n",
    "driver.get(\"http://www.city-data.com//advanced/search.php#body?fips=0&csize=l&sc=2&sd=1&states=ALL&near=&nam_crit1=1033&b1033=MIN&e1033=MAX&i1033=0&nam_crit2=1027&b1027=MIN&e1027=MAX&i1027=0&ps=20&p=0\")\n",
    "\n",
    "element = WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.CLASS_NAME, \"norm\")))\n",
    "\n",
    "html = driver.page_source\n",
    "get_data = BeautifulSoup(html, \"lxml\")\n",
    "table = get_data.find_all(\"table\", attrs={\"id\": \"sr\"})\n",
    "print(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# start firefox and scrape content\n",
    "driver = webdriver.Firefox()\n",
    "\n",
    "driver.get('http://www.city-data.com//advanced/search.php#body\\\n",
    "    ?fips=0&csize=l&sc=2&sd=1&states=ALL&near=&nam_crit1=1033&b1033=\\\n",
    "    MIN&e1033=MAX&i1033=0&nam_crit2=1027&b1027=MIN&e1027=MAX&i1027=0&ps=20&p=0')\n",
    "\n",
    "element = WebDriverWait(driver, 6).until(EC.presence_of_element_located((By.CLASS_NAME, \"norm\")))\n",
    "    \n",
    "html = driver.page_source    \n",
    "    \n",
    "soup = BeautifulSoup(html, \"lxml\")\n",
    "\n",
    "table = soup.find(\"table\", attrs={\"id\": \"sr\"})\n",
    "\n",
    "tr2_ = soup.find_all(\"tr\", class_='norm')\n",
    "\n",
    "tdf2=pd.DataFrame(tr2_, columns=['A,','B,','C,'])\n",
    "\n",
    "tdf2\n",
    "\n",
    " # save content to csv file\n",
    "\n",
    "file_to_save = 'tdf2.csv'\n",
    "    \n",
    "if not os.path.exists(file_to_save): \n",
    "        tdf2.to_csv(file_to_save,sep = \"|\",index=False)\n",
    "else:\n",
    "        tdf2.to_csv(file_to_save,sep = \"|\",mode = 'a',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " # save content to csv file\n",
    "\n",
    "file_to_save = 'tdf1.csv'\n",
    "    \n",
    "if not os.path.exists(file_to_save): \n",
    "        tdf1.to_csv(file_to_save,sep = \"|\",index=False)\n",
    "else:\n",
    "        tdf1.to_csv(file_to_save,sep = \"|\",mode = 'a',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### APPENDIX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Using BS, test if we can remove stuff which is commented\n",
    "site = 'http://www.city-data.com//advanced/search.php#body?fips=0&csize=l&sc=2&sd=1&states=ALL&near=&nam_crit1=1033&b1033=MIN&e1033=MAX&i1033=0&nam_crit2=1027&b1027=MIN&e1027=MAX&i1027=0&ps=20&p=0'\n",
    "hdr = {'User-Agent': 'Mozilla/5.0'}\n",
    "req = Request(site, headers=hdr)\n",
    "res = urlopen(req)\n",
    "rawpage = res.read().decode(\"utf-8\") \n",
    "page1 = rawpage.replace('<!--[MINFO41.075663,42.106227,37.821994,39.637437,42.358663,29.715929,41.185271,40.992121,39.001609,37.37139,37.458615,37.560199,40.93995,39.056453,40.863532,37.810003,40.078643,32.830178,41.216454,38.933477\\\n",
    "-73.482945,-87.73801,-122.231405,-104.947452,-71.28831,-95.432992,-73.768503,-73.787041,-77.283249,-122.137605,-122.200099,-122.356277,-73.826214,-77.237198,-74.2587,-121.913992,-82.820618,-96.801103,-73.373086,-77.27651\\\n",
    "918920,1782530,656938,813845,2577255,4877956,3650078,3665431,5132496,643294,603092,633798,3608532,2478650,3452620,606933,3953970,4833824,983430,5187240 MINFO]-->','')\n",
    "soup = BeautifulSoup(page1, \"html.parser\")\n",
    "temp=soup.find_all('div', class_=\"container-fluid\")  \n",
    "print(temp)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
